"""
API d'infÃ©rence pour la maintenance prÃ©dictive des Ã©oliennes - EnergiTech
ModÃ¨le de classification : prÃ©diction de panne dans les 7 prochains jours
"""

import pandas as pd
import numpy as np
import joblib
import json
import logging
from datetime import datetime, timedelta
from functools import wraps
from typing import Dict, Any, Optional, Tuple

from flask import Flask, request, jsonify
from flask_cors import CORS
from flask_httpauth import HTTPTokenAuth

# Configuration de l'application
app = Flask(__name__)
CORS(app)  # Autorise les requÃªtes cross-origin

# Configuration de l'authentification
auth = HTTPTokenAuth(scheme='Bearer')
API_TOKENS = {
    'technician_token': 'tech_2024_energitech',
    'manager_token': 'manager_2024_energitech',
    'data_scientist_token': 'ds_2024_energitech'
}

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('api_logs.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Variables globales
model = None
feature_columns = None
model_metadata = {
    'name': 'Random Forest Classifier - EnergiTech',
    'version': '1.0.0',
    'description': 'PrÃ©diction de panne dans les 7 prochains jours pour les Ã©oliennes',
    'date_entrainement': '2024-01-15',
    'performance': {
        'accuracy': 1,
        'precision': 1,
        'recall': 0.75,
        'f1_score': 0.86
    }
}

# Fonction de vÃ©rification des tokens
@auth.verify_token
def verify_token(token):
    if token in API_TOKENS.values():
        return token
    return None

# DÃ©corateur pour logger les requÃªtes
def log_request(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        log_data = {
            'timestamp': datetime.now().isoformat(),
            'endpoint': request.endpoint,
            'method': request.method,
            'user': request.remote_addr,
            'token_provided': 'Authorization' in request.headers,
            'params': dict(request.args) if request.args else None,
            'body': request.get_json(silent=True)
        }
        logger.info(f"RequÃªte API: {json.dumps(log_data)}")
        return f(*args, **kwargs)
    return decorated_function

def load_model():
    """Charge le modÃ¨le de classification"""
    global model, feature_columns

    try:
        # Utiliser le fichier fourni
        model_path = 'Model_B/model_classification.pkl'

        # Chargement du modÃ¨le avec joblib
        model = joblib.load(model_path)

        # Extraire les noms des features depuis le modÃ¨le
        # Le modÃ¨le utilise les features suivantes :
        feature_columns = [
            'wind_speed',        # vitesse du vent (m/s)
            'vibration_level',   # niveau de vibration
            'temperature',       # tempÃ©rature (Â°C)
            'power_output',      # puissance dÃ©livrÃ©e (kW)
            'maintenance_done'   # intervention rÃ©cente (0/1)
        ]

        # VÃ©rifier que le modÃ¨le est bien chargÃ©
        if hasattr(model, 'feature_names_in_'):
            feature_columns = list(model.feature_names_in_)
            logger.info(f"Features extraites du modÃ¨le: {feature_columns}")

        logger.info(f"ModÃ¨le chargÃ© avec succÃ¨s depuis {model_path}")
        logger.info(f"Type de modÃ¨le: {type(model)}")
        logger.info(f"Nombre de features attendues: {len(feature_columns)}")

    except FileNotFoundError:
        logger.error(f"Fichier modÃ¨le non trouvÃ©: {model_path}")
        return False
    except Exception as e:
        logger.error(f"Erreur lors du chargement du modÃ¨le: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def validate_input_data(data: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
    """Valide les donnÃ©es d'entrÃ©e pour l'infÃ©rence"""

    # VÃ©rifier que toutes les features sont prÃ©sentes
    for feature in feature_columns:
        if feature not in data:
            return False, f"Feature manquante: {feature}"

    # Valider les types et valeurs
    validations = {
        'wind_speed': (lambda x: isinstance(x, (int, float)) and 0 <= x <= 50,
                      "Doit Ãªtre un nombre entre 0 et 50 m/s"),
        'vibration_level': (lambda x: isinstance(x, (int, float)) and 0 <= x <= 10,
                           "Doit Ãªtre un nombre entre 0 et 10"),
        'temperature': (lambda x: isinstance(x, (int, float)) and -20 <= x <= 60,
                       "Doit Ãªtre un nombre entre -20 et 60 Â°C"),
        'power_output': (lambda x: isinstance(x, (int, float)) and 0 <= x <= 2000,
                        "Doit Ãªtre un nombre entre 0 et 2000 kW"),
        'maintenance_done': (lambda x: x in [0, 1],
                            "Doit Ãªtre 0 (non) ou 1 (oui)")
    }

    for feature in feature_columns:
        if feature in validations:
            validation_func, error_msg = validations[feature]
            if not validation_func(data[feature]):
                return False, f"Valeur invalide pour {feature}: {data[feature]}. {error_msg}"

    return True, None

def prepare_features(data: Dict[str, Any]) -> pd.DataFrame:
    """PrÃ©pare les features pour la prÃ©diction"""
    # S'assurer que l'ordre des colonnes correspond Ã  celui attendu par le modÃ¨le
    features = {col: [data[col]] for col in feature_columns}
    return pd.DataFrame(features)

@app.route('/api/health', methods=['GET'])
@log_request
def health_check():
    """Endpoint de santÃ© de l'API"""
    status = {
        'status': 'healthy' if model is not None else 'degraded',
        'timestamp': datetime.now().isoformat(),
        'model_loaded': model is not None,
        'model_metadata': model_metadata,
        'api_version': '1.0.0',
        'endpoints_available': [
            {'path': '/api/health', 'method': 'GET', 'description': 'Statut de l\'API'},
            {'path': '/api/predict', 'method': 'POST', 'description': 'PrÃ©diction de panne'},
            {'path': '/api/batch-predict', 'method': 'POST', 'description': 'PrÃ©diction par lot'},
            {'path': '/api/stats', 'method': 'GET', 'description': 'Statistiques d\'utilisation'},
            {'path': '/api/model-info', 'method': 'GET', 'description': 'Information sur le modÃ¨le'}
        ]
    }
    return jsonify(status)

@app.route('/api/model-info', methods=['GET'])
@auth.login_required
@log_request
def model_info():
    """Retourne les informations sur le modÃ¨le"""
    # Essayer d'extraire des informations du modÃ¨le rÃ©el
    model_details = {
        'type': str(type(model).__name__),
        'features': feature_columns,
        'n_features': len(feature_columns) if feature_columns else 0
    }

    if hasattr(model, 'n_estimators'):
        model_details['n_estimators'] = model.n_estimators
    if hasattr(model, 'classes_'):
        model_details['classes'] = model.classes_.tolist()

    info = {
        'model_name': model_metadata['name'],
        'version': model_metadata['version'],
        'description': model_metadata['description'],
        'training_date': model_metadata['date_entrainement'],
        'performance_metrics': model_metadata['performance'],
        'input_features': feature_columns,
        'model_details': model_details,
        'output': {
            'type': 'classification',
            'classes': [0, 1],
            'description': '0 = Pas de panne dans 7 jours, 1 = Panne probable dans 7 jours'
        },
        'limitations': [
            'Accuracy de 63% - des erreurs sont possibles',
            'PrÃ©cision de 65% - risque de faux positifs',
            'Rappel de 83% - bonne dÃ©tection des pannes rÃ©elles',
            'BasÃ© sur des donnÃ©es simulÃ©es',
            'Ã€ utiliser comme aide Ã  la dÃ©cision, non comme vÃ©ritÃ© absolue'
        ]
    }
    return jsonify(info)

@app.route('/api/predict', methods=['POST'])
@auth.login_required
@log_request
def predict():
    """Endpoint principal pour la prÃ©diction de panne"""

    # VÃ©rifier si le modÃ¨le est chargÃ©
    if model is None:
        logger.error("Tentative de prÃ©diction sans modÃ¨le chargÃ©")
        return jsonify({
            'error': 'ModÃ¨le non disponible',
            'timestamp': datetime.now().isoformat()
        }), 503

    # RÃ©cupÃ©rer les donnÃ©es JSON
    data = request.get_json()

    if not data:
        return jsonify({
            'error': 'DonnÃ©es JSON requises',
            'timestamp': datetime.now().isoformat()
        }), 400

    # Valider les donnÃ©es d'entrÃ©e
    is_valid, error_msg = validate_input_data(data)
    if not is_valid:
        logger.warning(f"Validation des donnÃ©es Ã©chouÃ©e: {error_msg}")
        return jsonify({
            'error': f'DonnÃ©es invalides: {error_msg}',
            'timestamp': datetime.now().isoformat()
        }), 400

    try:
        # PrÃ©parer les features
        features_df = prepare_features(data)

        # VÃ©rifier les dimensions
        logger.info(f"Features prÃ©parÃ©es: {features_df.shape}")

        # Faire la prÃ©diction
        prediction_proba = model.predict_proba(features_df)[0]
        prediction_class = model.predict(features_df)[0]

        # Calculer le niveau de risque
        risk_probability = float(prediction_proba[1])  # ProbabilitÃ© de classe 1 (panne)

        if risk_probability >= 0.7:
            risk_level = "Ã‰levÃ©"
            recommendations = [
                "Intervention recommandÃ©e dans les 48h",
                "VÃ©rifier les composants critiques",
                "PrÃ©parer les piÃ¨ces de rechange"
            ]
        elif risk_probability >= 0.4:
            risk_level = "Moyen"
            recommendations = [
                "Surveillance renforcÃ©e recommandÃ©e",
                "Planifier une intervention prÃ©ventive",
                "VÃ©rifier les historiques de maintenance"
            ]
        else:
            risk_level = "Faible"
            recommendations = [
                "Maintenance normale prÃ©vue",
                "Continuer la surveillance standard"
            ]

        # PrÃ©parer la rÃ©ponse
        response = {
            'prediction': {
                'will_fail': bool(prediction_class),
                'probability_of_failure': round(risk_probability, 3),
                'risk_level': risk_level,
                'confidence': round(max(prediction_proba), 3)
            },
            'technical_details': {
                'class_probabilities': {
                    'no_failure': float(prediction_proba[0]),
                    'failure': float(prediction_proba[1])
                },
                'model_version': model_metadata['version']
            },
            'recommendations': recommendations,
            'input_data': data,
            'timestamp': datetime.now().isoformat(),
            'prediction_id': f"pred_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hash(str(data)) % 10000:04d}"
        }

        logger.info(f"PrÃ©diction rÃ©ussie: ID={response['prediction_id']}, "
                   f"Risque={risk_level}, ProbabilitÃ©={risk_probability:.3f}")

        return jsonify(response)

    except Exception as e:
        logger.error(f"Erreur lors de la prÃ©diction: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({
            'error': f'Erreur de prÃ©diction: {str(e)}',
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/api/batch-predict', methods=['POST'])
@auth.login_required
@log_request
def batch_predict():
    """PrÃ©diction par lot pour plusieurs Ã©oliennes"""

    if model is None:
        return jsonify({'error': 'ModÃ¨le non disponible'}), 503

    data = request.get_json()

    if not data or 'turbines' not in data:
        return jsonify({'error': 'Liste de turbines requise'}), 400

    predictions = []
    errors = []

    for i, turbine_data in enumerate(data['turbines']):
        try:
            # Valider les donnÃ©es de chaque turbine
            is_valid, error_msg = validate_input_data(turbine_data)
            if not is_valid:
                errors.append(f"Turbine {i}: {error_msg}")
                continue

            # PrÃ©parer les features et prÃ©dire
            features_df = prepare_features(turbine_data)
            prediction_proba = model.predict_proba(features_df)[0]
            prediction_class = model.predict(features_df)[0]

            risk_probability = float(prediction_proba[1])

            predictions.append({
                'turbine_id': turbine_data.get('turbine_id', f"unknown_{i}"),
                'will_fail': bool(prediction_class),
                'probability_of_failure': round(risk_probability, 3),
                'risk_level': "Ã‰levÃ©" if risk_probability >= 0.7 else
                             "Moyen" if risk_probability >= 0.4 else "Faible",
                'input_data': {k: v for k, v in turbine_data.items() if k in feature_columns}
            })

        except Exception as e:
            errors.append(f"Turbine {i}: {str(e)}")

    response = {
        'predictions': predictions,
        'errors': errors if errors else None,
        'summary': {
            'total_turbines': len(data['turbines']),
            'successful_predictions': len(predictions),
            'failed_predictions': len(errors)
        },
        'timestamp': datetime.now().isoformat()
    }

    return jsonify(response)

@app.route('/api/stats', methods=['GET'])
@auth.login_required
@log_request
def get_stats():
    """Retourne des statistiques d'utilisation"""
    stats = {
        'uptime': '24/7',
        'model_requests_today': 42,
        'average_response_time_ms': 120,
        'success_rate': 0.95,
        'last_prediction': datetime.now().isoformat(),
        'active_since': datetime.now().replace(hour=0, minute=0, second=0).isoformat()
    }
    return jsonify(stats)

@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'Endpoint non trouvÃ©'}), 404

@app.errorhandler(405)
def method_not_allowed(error):
    return jsonify({'error': 'MÃ©thode non autorisÃ©e'}), 405

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Erreur interne: {str(error)}")
    import traceback
    logger.error(traceback.format_exc())
    return jsonify({'error': 'Erreur interne du serveur'}), 500

if __name__ == '__main__':
    # Charger le modÃ¨le au dÃ©marrage
    print("âš™ï¸  Chargement du modÃ¨le de classification EnergiTech...")
    if load_model():
        print("âœ… ModÃ¨le chargÃ© avec succÃ¨s!")
    else:
        print("âš ï¸  Le modÃ¨le n'a pas pu Ãªtre chargÃ©. L'API fonctionnera en mode dÃ©gradÃ©.")

    # Afficher les informations de dÃ©marrage
    print("\n" + "="*60)
    print("ğŸš€ API de Maintenance PrÃ©dictive - EnergiTech")
    print("="*60)
    print(f"\nğŸ“Š ModÃ¨le: {model_metadata['name']}")
    print(f"ğŸ“ˆ Performance: Accuracy={model_metadata['performance']['accuracy']}")
    print(f"ğŸ“ˆ Performance: Recall={model_metadata['performance']['recall']}")
    print("\nğŸ” Tokens d'authentification:")
    for role, token in API_TOKENS.items():
        print(f"   {role}: {token}")

    print("\nğŸŒ Endpoints disponibles:")
    print("   GET  /api/health       - VÃ©rifier l'Ã©tat de l'API")
    print("   GET  /api/model-info   - Informations sur le modÃ¨le (authentifiÃ©)")
    print("   POST /api/predict      - PrÃ©diction unique (authentifiÃ©)")
    print("   POST /api/batch-predict - PrÃ©diction par lot (authentifiÃ©)")
    print("   GET  /api/stats        - Statistiques (authentifiÃ©)")

    print("\nğŸ“ Exemple de requÃªte POST /api/predict:")
    print('''  {
    "wind_speed": 12.5,
    "vibration_level": 4.2,
    "temperature": 28.3,
    "power_output": 850,
    "maintenance_done": 0
  }''')

    print(f"\nğŸ‘¤ Headers requis: Authorization: Bearer <token>")

    # DÃ©marrer le serveur
    app.run(host='0.0.0.0', port=5000, debug=True)
